# -*- coding: utf-8 -*-
"""notebookfb0131f21c

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/notebookfb0131f21c-92bcff31-3c79-4720-a65d-cbe39d3220ad.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20240508/auto/storage/goog4_request%26X-Goog-Date%3D20240508T133911Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D935c5be03d9310ccec8365ba69244a0e1bb04cacca270abd470b07f9a0e1d2876d4b87191c99c8dc8354173b3e1de630216751875b64836079e55912fe0add39f7f95b2f3240cc2e39c25d1feecff267f77956bed680deb5c12857a7c51aa4f7b8a476cc21a4d8bd0de4662947d2af70dab663e1c180ae1c323eb9a2cf18fe02b306026f997e525a0cc68f55e83c69aca0ff433adee92b03916277e37950f7d6091aee2b57274917a7532948c97f7318d5738ea37a20a7fead4cb9c9699c031c5a5be34126ba84e907902ecbbea2ab6bd568253af44ef047baabb309c1ea00c7115ac0b883d7e42791be28c3bf15c63e0afc513523c0237a93e6df028941ab43
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES
# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = 'titanic:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F3136%2F26502%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240508%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240508T133911Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D212e585da8d08748729da6664a13d2e38d4cf63aa889e2d4ceef9ae3c063b2ec5b508626964d5c8579b874a68d5a48735db0e0f9f5278b9c57e8c34e6e788959e4647d608d8ee7daac74778f689075791353cc56178be6ae378bcbad6e3db7f2f520df8aa46b371c53e31db4c86a82dcc79ea1eceea528438cf5ab5aa82dad762b84fcdd95ed91f9ca8a91c5598ad0e4b0abdc04af215abdc10e7b8c704214682999d2a24df9ab8f6adb1f0f7e4d24763b5dcbb81eb398a61976c924f9be1f92597d9f06a9fbcaac62a5a73971d375d4f743bd891cf388ca80187c9adf793441eea9f38092460da91aa9ed5ad07daf22c3548151960a69d3383febbc032fa0b7'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

train_data_path = '/kaggle/input/titanic/train.csv'
test_data_path = '/kaggle/input/titanic/test.csv'

titanic_data = pd.read_csv(train_data_path)

missing_values = titanic_data.isnull().sum()
print("Missing Values:\n", missing_values)

titanic_data['Age'] = titanic_data['Age'].fillna(titanic_data['Age'].mean())
titanic_data['Cabin'] = titanic_data['Cabin'].fillna('Unknown')
titanic_data['Embarked'] = titanic_data['Embarked'].fillna(titanic_data['Embarked'].mode()[0])

titanic_data['Survived'] = titanic_data['Survived'].astype('category')
titanic_data['Pclass'] = titanic_data['Pclass'].astype('category')
titanic_data['Sex'] = titanic_data['Sex'].astype('category')
titanic_data['Embarked'] = titanic_data['Embarked'].astype('category')

print("Descriptive Statistics:\n", titanic_data.describe(include='all'))

titanic_data[['Age', 'Fare']].hist(bins=20, figsize=(10, 5))
plt.show()

numeric_data = titanic_data.select_dtypes(include=['float64', 'int64'])

correlation_matrix = numeric_data.corr()
print("Correlation Matrix:\n", correlation_matrix)

sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()

sns.barplot(x='Pclass', y='Survived', data=titanic_data)
plt.title("Survival Rate by Passenger Class")
plt.show()

sns.barplot(x='Sex', y='Survived', data=titanic_data)
plt.title("Survival Rate by Gender")
plt.show()

sns.barplot(x='Embarked', y='Survived', data=titanic_data)
plt.title("Survival Rate by Embarked Location")
plt.show()